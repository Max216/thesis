\babel@toc {english}{}
\contentsline {figure}{\numberline {1}{\ignorespaces A sample ontology of animals to illustrate the lexical relations \textit {Hypernomy} and \textit {Holonymy}.}}{11}{figure.1}
\contentsline {figure}{\numberline {2}{\ignorespaces The architecture of the sentence-encoding component within the Shortcut-Stacked-Encoder, taken from \cite {nie2017shortcut}.}}{12}{figure.2}
\contentsline {figure}{\numberline {3}{\ignorespaces Example of different synsets of the lemma ``table'' (only noun senses) within WordNet, taken from \href {http://wordnetweb.princeton.edu}{http://wordnetweb.princeton.edu}.}}{16}{figure.3}
\contentsline {figure}{\numberline {4}{\ignorespaces General architecture of a \ac {RNN} (left). Example sentence in an unrolled \ac {RNN} (right).}}{27}{figure.4}
\contentsline {figure}{\numberline {5}{\ignorespaces Visualized example of extracting interpretable information of the max-pooled seentence representations with a dimensionality of 3.}}{27}{figure.5}
\contentsline {figure}{\numberline {6}{\ignorespaces The standard deviation within a dimension of sentence representations (x-axis) by the amount of dimensions with the given standard deviation.}}{28}{figure.6}
\contentsline {figure}{\numberline {7}{\ignorespaces An extraction of a grid-plot, showing dimensions with the position within the sentence of the word, responsible for the dimensional value.}}{29}{figure.7}
\contentsline {figure}{\numberline {8}{\ignorespaces An extraction of a grid-plot, showing syntatical information using the \ac {POS} tag with pre-sorted rows to have a single dominant label.}}{31}{figure.8}
\contentsline {figure}{\numberline {9}{\ignorespaces An extraction of a grid-plot, gender specific female using only sentences with words of pre-defined wordlists.}}{32}{figure.9}
\contentsline {figure}{\numberline {10}{\ignorespaces Representation visualitation with respect to genders of dimension \texttt {199} (left) and dimension \texttt {602} (right).}}{33}{figure.10}
\contentsline {figure}{\numberline {11}{\ignorespaces Detailed representation visualitation of different terms for human males of dimension \texttt {199} (left) and dimension \texttt {602} (right).}}{33}{figure.11}
\contentsline {figure}{\numberline {12}{\ignorespaces Detailed representation visualitation of different terms for human females of dimension \texttt {845} (left) and dimension \texttt {311} (right).}}{34}{figure.12}
\contentsline {figure}{\numberline {13}{\ignorespaces Dimension \texttt {713} encoding verbs (left) and dimension \texttt {2020} encoding adjectives.}}{38}{figure.13}
\contentsline {figure}{\numberline {14}{\ignorespaces Dimension \texttt {757}, encoding the subjects (left), and dimension \texttt {1840} encoding objects (right) of sentences.}}{39}{figure.14}
\contentsline {figure}{\numberline {15}{\ignorespaces Word alignments of an entailing sentence pair either by counting all shared dimensions (left) or only dimensions with at least a value of 0.2 (right).}}{41}{figure.15}
\contentsline {figure}{\numberline {16}{\ignorespaces Visualitation of an entailing sample with applied element-wise multiplication either using the mean (left) or maximum (right) product of all shared dimensions for each word pair.}}{42}{figure.16}
\contentsline {figure}{\numberline {17}{\ignorespaces Visualitation of a contradicting sample by counting meaningful shared dimensions (left) and meaningful distinct dimensions 8right) amongst pairs of words.}}{42}{figure.17}
\contentsline {figure}{\numberline {18}{\ignorespaces Dimension-wise visualitation of distinct information represented by \textit {sitting} in the premise and \textit {standing} in the hypothesis.}}{43}{figure.18}
\contentsline {figure}{\numberline {19}{\ignorespaces Visualitation of a sample sentence pair with explanatory guides for interpretation.}}{44}{figure.19}
\contentsline {figure}{\numberline {20}{\ignorespaces Visualization of 150 sentence pairs ($p$, $h$), correctly labelled as entailment.}}{45}{figure.20}
\contentsline {figure}{\numberline {21}{\ignorespaces Visualization of samples predicted as entailment (left) and neutral (right) after swapping $p$ and $h$.}}{46}{figure.21}
\contentsline {figure}{\numberline {22}{\ignorespaces Visualitazion of 150 sentence pairs ($p$, $h$) correctly labelled as \textit {neutral} (left) and \textit {contradiction} (right).}}{47}{figure.22}
\contentsline {figure}{\numberline {23}{\ignorespaces Example of a \ac {HIT} in Amazon Mechanical Turk.}}{56}{figure.23}
\contentsline {figure}{\numberline {24}{\ignorespaces Accuracy by cosine similarity reached by Decomposable Attention (without fine-tuned embeddings).}}{61}{figure.24}
\contentsline {figure}{\numberline {25}{\ignorespaces Accuracy by word freqency for Residual-Stacked Encoder and ESIM.}}{62}{figure.25}
\contentsline {figure}{\numberline {26}{\ignorespaces Architecture of the Residual-Stacked Encoder with multitask learning for the sentence-representations.}}{66}{figure.26}
\contentsline {figure}{\numberline {27}{\ignorespaces Comparison of contradicting samples (different w.r.t. correctness from Residual-Stacked Encoder\textsuperscript {$\dagger $}). for Hypernyms-5, by the amont of shared hypernym embeddings.}}{73}{figure.27}
\contentsline {figure}{\numberline {28}{\ignorespaces Aligned $p$ and $h$ for all contradicting sampes, covered by the fused WordNet information, correctly predicted (left) or mis-predicted (right).}}{76}{figure.28}
\contentsline {figure}{\numberline {29}{\ignorespaces Aligned $p$ and $h$, correctly predicted (left) and mis-predicted (right) for multitask-learned \textit {300D-0.75 STD}.}}{76}{figure.29}
\contentsline {figure}{\numberline {30}{\ignorespaces Aligned $p$ and $h$, of contradicting (left) and entailing (right) samples for multitask-learned \textit {300D-0.75 max-pool}.}}{77}{figure.30}
