\section{Conclusion and future work}
In this work we showed at the sampe of \ac{SNLI}, that even though being intended to improve \ac{NLU}, the high performance gained by state-of-the-art models for \ac{NLI} does not reflect the actual \ac{NLU} capabilities. All models performed significantly lower on our adversarial dataset, derived from the original train-set but excluded  \ac{SNLI}-specific patterns. Even though \ac{KIM} performed quite well, future work may find ways to integrate more data or methods to deal with lexical inferences in context to improve the performance, which has not yet met the limit. We attempted to improvce the performance on this new dataset using WordNet information for a sentence-encoding model. Here, we leveraged from the max-pooled sentence-encoding and showed that this can be used to understand the dimensional values and sentence-representations, generated by the model. In addition to showing that this information can indeed be used to change the representations in a meaningful way, our inisghts gained here, have also shown to be useful for an intrinsic analysis of the sentence-representations of the experiments incorporating WordNet. Future work can develop deper insights on these representations on a broader range of data and models, to enable more meaningful analysis or even adaptions. This may lead to better defined helper-tasks for multitask-learning approaches, such that the dimensions are adapted under consideration of the original sentence encoding scheme. Finally we evaluated in our approaches to incorporate WordNet, that this should be done in a general and very easy to identify way, in order to be relevant enough to overcome diminant patterns in a dataset. Especially for sentence-encoding models this seems very challenging at the moment, future work may leverage from structures like memory networks \citep{sukhbaatar2015end}, to do so.

\section*{Acknowledgements}
Special Thanks to Yoav Goldberg and Vered Shwartz, for their continuous support and guiding for my master thesis, while still giving e the freedom to pursue my own ideas. I am also thankful for Andreas Rücklé and Andreas Hanselowski for supervising me from Germany, and even though the far distance assited with valuable advice and discussions. The possibility for me to conduct my thesis at Bar-Ilan was enabled by Iryna Gurevych an Yoav Goldberg within a very short time and without complications, which I am also very thankful for. Finally I want to thank the remainder of the group at Bar-Ilan for a great stay. Additionally, Corinna Neureither double checked my final thesis, and is to blame for any remaining spelling errors.